{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_pdf.py\n",
    "import gen_pdfs.py\n",
    "import dns_plotter.py\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot DNS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '/projects/exact/Shashank/plt_DRM_0.7_1095_ML_Output'\n",
    "plot_dns(fdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the PDFs from the DNS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = \"dice_0004\"\n",
    "datadir = os.path.abspath('data')\n",
    "pdf, bins, means = gen_pdf_from_dice(os.path.join(datadir, f\"{dice}.npz\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load the pdf, bins, and means (if they have already been generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_pickle(os.path.join(datadir, f\"{dice}_pdfs.gz\"))\n",
    "bins = pd.read_pickle(os.path.join(datadir, \"bins.gz\"))\n",
    "means = pd.read_pickle(os.path.join(datadir, f\"{dice}_src_pv_means.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have all the dice, you can concatenate them into one large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = [\"dice_0001\",\"dice_0002\",\"dice_0003\",\"dice_0004\",\"dice_0005\"]\n",
    "pdf = pd.concat([pd.read_pickle(os.path.join(datadir, f\"{dice}_pdfs.gz\")) for dice in dices], ignore_index=True)\n",
    "means = pd.concat([pd.read_pickle(os.path.join(datadir, f\"{dice}_src_pv_means.gz\")) for dice in dices], ignore_index=True)\n",
    "pdf.to_pickle(os.path.join(datadir, \"dices_pdfs.gz\"))\n",
    "means.to_pickle(os.path.join(datadir, \"dices_src_pv_means.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how to get the bin edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbin_edges = utilities.midpoint_to_edges(np.unique(bins.Cbins))\n",
    "zbin_edges = utilities.midpoint_to_edges(np.unique(bins.Zbins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot slices in the dices, the input space and some sample pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[plot_dice_slices(os.path.join(datadir, f\"{dice}.npz\")) for dice in dices]\n",
    "\n",
    "for dice in dices:\n",
    "    pdf = pd.read_pickle(os.path.join(datadir, f\"{dice}_pdfs.gz\"))\n",
    "    plot_input_space(pdf, fname=f\"inputs_{dice}.pdf\")\n",
    "    \n",
    "# Find PDFs with points closest to these:\n",
    "points = pd.DataFrame({'Z':[0, 0.4, 0.6255, 0.6714,0.8, 0.9252],\n",
    "                       'Zvar': [0, 0.0066, 0.0134, 0.0128, 0.01, 0.0043],\n",
    "                       'C':[0, 0.0269, 0.0318, 0.0822, 0.05, 0.1209],\n",
    "                       'Cvar':[0, 0.0006, 0.0016, 0.0034, 0.0029, 0.0046]})\n",
    "idx = [closest_point(points.loc[i,:], pdf.loc[:,points.columns]).name for i in points.index]\n",
    "plot_pdfs(pdf.loc[idx], means.loc[idx], bins)\n",
    "\n",
    "# Or (fewer points)\n",
    "points = pd.DataFrame({'Z':[0, 0.4, 0.6714, 0.9252],\n",
    "                       'Zvar': [0, 0.0066, 0.0128, 0.0043],\n",
    "                       'C':[0, 0.0269, 0.0822, 0.1209],\n",
    "                       'Cvar':[0, 0.0006, 0.0034, 0.0046]})\n",
    "idx = [closest_point(points.loc[i,:], pdf.loc[:,points.columns]).name for i in points.index]\n",
    "plot_pdfs(pdf.loc[idx], means.loc[idx], bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find distances between PDFs in different dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdf_distances(\"dice_0004\")\n",
    "plot_pdf_distances(\"dice_0004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xdev, Xtest, Ytrain, Ydev, Ytest, scaler = gen_training(pdf, dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load the training data (if it has already been generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.read_pickle(os.path.join(datadir, f\"{dice}_xtrain.gz\"))\n",
    "Xdev = pd.read_pickle(os.path.join(datadir, f\"{dice}_xdev.gz\"))\n",
    "Ytrain = pd.read_pickle(os.path.join(datadir, f\"{dice}_ytrain.gz\"))\n",
    "Ydev = pd.read_pickle(os.path.join(datadir, f\"{dice}_ydev.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, one might need to switch scalers (e.g. you train on one dice and want to predict on another)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dice_0002 = joblib.load(os.path.join(datadir, \"dice_0002_scaler.pkl\"))\n",
    "scaler_dice_0003 = joblib.load(os.path.join(datadir, \"dice_0003_scaler.pkl\"))\n",
    "Xtrain = utilities.switch_scaler(Xtrain, scaler_dice_0003, scaler_dice_0002)\n",
    "Xdev = utilities.switch_scaler(Xdev, scaler_dice_0003, scaler_dice_0002);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF predictions with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_rf, mdev_rf, RF = rf_training(Xtrain, Xdev, Ytrain, Ydev)\n",
    "plot_result( Ytrain, mtrain_rf, Ydev, mdev_rf, pdf.loc[Xdev.index,Xdev.columns], bins, fname = \"RF.pdf\")\n",
    "conv_rf = convolution_means(mdev_rf, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_rf, fname = \"convolution_RF.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_lr, mdev_lr, LR = lr_training(Xtrain, Xdev, Ytrain, Ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_pr, mdev_pr, PR = pr_training(Xtrain, Xdev, Ytrain, Ydev, order=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_dnn, mdev_dnn, DNN = dnn_training(Xtrain, Xdev, Ytrain, Ydev, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load a pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.double\n",
    "vh = VariableHandler(device=device, dtype=dtype)\n",
    "batch_size = 64\n",
    "input_size = Xtrain.shape[1]\n",
    "layer_sizes = [256, 512, Ytrain.shape[1]]\n",
    "DNN = Net(input_size, layer_sizes, vh).to(device=device, dtype=dtype)\n",
    "DNN.load('DNN.pkl')\n",
    "mtrain_dnn = DNN.predict(Xtrain)\n",
    "mdev_dnn = DNN.predict(Xdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result( Ytrain, mtrain_dnn, Ydev, mdev_dnn, pdf.loc[Xdev.index,Xdev.columns], bins, fname = \"DNN.pdf\")\n",
    "conv_dnn = convolution_means(mdev_dnn, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_dnn, fname = \"convolution_DNN.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate of feature importance through the shuffled input loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dnn = shuffled_input_loss(DNN, Xdev, Ydev)\n",
    "imp_dnn.div(imp_dnn.original, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF predictions with generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_cvae, mdev_cvae, cvae = cvae_training(Xtrain, Xdev, Ytrain, Ydev, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load a pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "vh = VariableHandler(device=device, dtype=torch.double)\n",
    "nlabels = Xtrain.shape[1]\n",
    "input_size = Ytrain.shape[1]\n",
    "batch_size = 64\n",
    "encoder_layer_sizes = [input_size + nlabels, 512, 256]\n",
    "latent_size = 10\n",
    "decoder_layer_sizes = [256, 512, input_size]\n",
    "\n",
    "cvae = CVAE(\n",
    "        encoder_layer_sizes=encoder_layer_sizes,\n",
    "        latent_size=latent_size,\n",
    "        decoder_layer_sizes=decoder_layer_sizes,\n",
    "        nlabels=nlabels,\n",
    "        vh=vh,\n",
    "    ).to(device=device)\n",
    "cvae.load(\"CVAE.pkl\")\n",
    "\n",
    "mtrain_cvae = cvae.predict(Xtrain)\n",
    "mdev_cvae = cvae.predict(Xdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result( Ytrain, mtrain_cvae, Ydev, mdev_cvae, pdf.loc[Xdev.index,Xdev.columns], bins, fname='CVAE.pdf')\n",
    "conv_cvae = convolution_means(mdev_cvae, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_cvae, fname = \"convolution_CVAE.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the model to predict on all the dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dice_0002 = joblib.load(os.path.join(datadir, \"dice_0002_scaler.pkl\"))\n",
    "predict_all_dice(cvae, scaler_dice_0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain_cgan, mdev_cgan, cgan = cgan_training(Xtrain, Xdev, Ytrain, Ydev, use_gpu=True)\n",
    "plot_result( Ytrain, mtrain_cgan, Ydev, mdev_cgan, pdf.loc[Xdev.index,Xdev.columns], bins, fname='CGAN.pdf')\n",
    "conv_cgan = convolution_means(mdev_cgan, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_cgan, fname = \"convolution_CGAN.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF predictions with analytical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delta-delta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DD(zbin_edges, cbin_edges)\n",
    "mtrain_dd = dd.predict(pdf.loc[Xtrain.index,['C','Z']])\n",
    "mdev_dd = dd.predict(pdf.loc[Xdev.index,['C','Z']])\n",
    "summarize_training(Ytrain, mtrain_dd, Ydev, mdev_dd, fname=\"DD.log\")\n",
    "plot_result( Ytrain, mtrain_dd, Ydev, mdev_dd, pdf.loc[Xdev.index,Xdev.columns], bins, fname = \"DD.pdf\")\n",
    "conv_dd = convolution_means(mdev_dd, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_dd, fname = \"convolution_DD.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beta-delta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = BD(zbin_edges, cbin_edges)\n",
    "mtrain_bd = bd.predict(pdf.loc[Xtrain.index,['C','Z','Zvar']])\n",
    "mdev_bd = bd.predict(pdf.loc[Xdev.index,['C','Z','Zvar']])\n",
    "summarize_training(Ytrain, mtrain_bd, Ydev, mdev_bd, fname=\"BD.log\")\n",
    "plot_result( Ytrain, mtrain_bd, Ydev, mdev_bd, pdf.loc[Xdev.index,Xdev.columns], bins, fname = \"BD.pdf\")\n",
    "conv_bd = convolution_means(mdev_bd, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_bd, fname = \"convolution_BD.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beta-beta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = BB(zbin_edges, cbin_edges)\n",
    "mtrain_bb = bb.predict(pdf.loc[Xtrain.index,['C','Cvar','Z','Zvar']])\n",
    "mdev_bb = bb.predict(pdf.loc[Xdev.index,['C','Cvar','Z','Zvar']])\n",
    "summarize_training(Ytrain, mtrain_bb, Ydev, mdev_bb, fname=\"BB.log\")\n",
    "plot_result( Ytrain, mtrain_bb, Ydev, mdev_bb, pdf.loc[Xdev.index,Xdev.columns], bins, fname = \"BB.pdf\")\n",
    "conv_bb = convolution_means(mdev_bb, means.loc[Ydev.index])\n",
    "plot_scatter(pdf.SRC_PV.loc[Ydev.index], conv_bb, fname = \"convolution_BB.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, medium, bad beta models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index\n",
    "m_bb = bb.predict(pdf.loc[:,['C','Cvar','Z','Zvar']])\n",
    "jsd_bb = calculate_jsd(pdf.loc[:,Ytrain.columns], m_bb)\n",
    "idx = [jsd_bb.argmin(), np.fabs(jsd_bb - np.log(2)/2).argmin(), jsd_bb.argmax()]\n",
    "\n",
    "# Plot PDFs\n",
    "for i, index in enumerate(idx):\n",
    "    m_bb = {'BB': bb.predict(pdf.loc[[index],['C','Cvar','Z','Zvar']])}\n",
    "    plot_pdfs(pdf.loc[[index]], means.loc[[index]], bins, fname=f\"pdfs_{index}.pdf\", models=m_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting on a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pdf.xc < 0\n",
    "Xtrain_sub = Xtrain.loc[idx.loc[Xtrain.index]]\n",
    "Xdev_sub = Xdev.loc[idx.loc[Xdev.index]]\n",
    "Ytrain_sub = Ytrain.loc[idx.loc[Ytrain.index]]\n",
    "Ydev_sub = Ydev.loc[idx.loc[Ydev.index]]\n",
    "\n",
    "mtrain_dnn, mdev_dnn, DNN = dnn_training(Xtrain_sub, Xdev_sub, Ytrain_sub, Ydev_sub, use_gpu=True)\n",
    "\n",
    "dnn_h = predict_all_dice(DNN, scaler_dice_0004, half=True)\n",
    "plot_dice_predictions({'DNN':dnn_h})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the models and then:\n",
    "pt = prediction_times({'RF':RF, 'DNN':DNN, 'CVAE': cvae}, Xdev, Ydev)\n",
    "pt.loc[:,['model','time','error']].to_latex()\n",
    "\n",
    "# For the analytical models, you can do\n",
    "pt = prediction_times({'BB': bb}, pdf.loc[Xdev.index,['C','Cvar','Z','Zvar']], Ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd = pd.DataFrame({'RF': calculate_jsd(Ydev, mdev_rf), \n",
    "                    'DNN': calculate_jsd(Ydev, mdev_dnn), \n",
    "                    'CVAE': calculate_jsd(Ydev, mdev_cvae), \n",
    "                    'BB': calculate_jsd(Ydev, mdev_bb)})\n",
    "plot_jsd(jsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutions = pd.DataFrame({'RF': convolution_means(mdev_rf, means.loc[Ydev.index]), \n",
    "                             'DNN': convolution_means(mdev_dnn, means.loc[Ydev.index]), \n",
    "                             'CVAE': convolution_means(mdev_cvae, means.loc[Ydev.index]),\n",
    "                             'BB': convolution_means(mdev_bb, means.loc[Ydev.index])})\n",
    "plot_convolution(pdf.loc[Ydev.index], convolutions, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, bad, medium PDFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on BB predictions (use with dice_0004)\n",
    "jsd_bb = calculate_jsd(Ydev, mdev_bb)\n",
    "idx = [jsd_bb.argmin(), np.fabs(jsd_bb - np.log(2)/2).argmin(), jsd_bb.argmax()]\n",
    "for i, index in zip(idx, Ydev.index[idx]):\n",
    "    model_pdfs = {'RF': mdev_rf[np.newaxis, i,:],\n",
    "                  'DNN': mdev_dnn[np.newaxis, i,:],\n",
    "                  'CVAE': mdev_cvae[np.newaxis, i,:],\n",
    "                  'BB': mdev_bb[np.newaxis, i,:]}\n",
    "    plot_pdfs(pdf.loc[[index]], means.loc[[index]], bins, fname=f\"pdfs_{index}.pdf\", models=model_pdfs)\n",
    "    \n",
    "# based on PDF of DNN predictions and higher filtered reaction rates (use with dices_skip)\n",
    "omega_lim = 15\n",
    "jsd_dnn = calculate_jsd(Ydev, mdev_dnn)\n",
    "\n",
    "points = [jsd_dnn[pdf.SRC_PV.loc[Ydev.index].values > omega_lim].min(),\n",
    "          np.median(jsd_dnn[pdf.SRC_PV.loc[Ydev.index].values > omega_lim]),\n",
    "          jsd_dnn[pdf.SRC_PV.loc[Ydev.index].values > omega_lim][np.fabs(jsd_dnn[pdf.SRC_PV.loc[Ydev.index].values > omega_lim] - 0.1).argmin()],\n",
    "          jsd_dnn[pdf.SRC_PV.loc[Ydev.index].values > omega_lim].max()]\n",
    "idx = [np.fabs(jsd_dnn - point).argmin() for point in points]\n",
    "\n",
    "src_pv_err_dnn = np.fabs(pdf.SRC_PV.loc[Ydev.index] - convolution_means(mdev_dnn, means.loc[Ydev.index])).values\n",
    "\n",
    "\n",
    "for i, index in zip(idx, Ydev.index[idx]):\n",
    "    model_pdfs = {'RF': mdev_rf[np.newaxis, i,:],\n",
    "                  'DNN': mdev_dnn[np.newaxis, i,:],\n",
    "                  'CVAE': mdev_cvae[np.newaxis, i,:],\n",
    "                  'BB': mdev_bb[np.newaxis, i,:]}\n",
    "    plot_pdfs(pdf.loc[[index]], means.loc[[index]], bins, fname=f\"pdfs_{index}.pdf\", models=model_pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions across dices (load models first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbp = predict_all_dice(bb, None)\n",
    "rf_4 = predict_all_dice(RF, scaler_dice_0004)\n",
    "dnn_4 = predict_all_dice(DNN, scaler_dice_0004)\n",
    "cvae_4 = predict_all_dice(cvae, scaler_dice_0004)\n",
    "predictions_4 = {'RF': rf_4, 'DNN':dnn_4, 'CVAE': cvae_4, 'BB': bbp}\n",
    "with open(os.path.join(datadir, 'predictions_4.pkl'), 'wb') as f:\n",
    "    pickle.dump(predictions_4, f, pickle.HIGHEST_PROTOCOL)\n",
    "# or load\n",
    "with open(os.path.join(datadir, 'predictions_4.pkl'), 'rb') as f:\n",
    "    predictions_4 = pickle.load(f)\n",
    "# plot\n",
    "plot_dice_predictions(predictions_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layerwise relevance propagation (LRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dices_skip = joblib.load(os.path.join(datadir, \"dices_skip_scaler.pkl\"))\n",
    "lrps = lrp_all_dice(DNN, scaler_dices_skip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
